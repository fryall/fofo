{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMOcYKHI7kTwUSQGNrThRh5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fryall/fofo/blob/main/old_copy.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UUdsqQJv9ScC"
      },
      "outputs": [],
      "source": [
        "import os,glob\n",
        "import cv2\n",
        "from tqdm._tqdm_notebook import tqdm_notebook as tqdm # import was correct\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn import preprocessing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Convolution2D, Dropout, Dense,MaxPooling2D,GlobalAveragePooling2D\n",
        "from keras.layers import BatchNormalization\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import Flatten, Dense, InputLayer"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install split-folders"
      ],
      "metadata": {
        "id": "_SolqbdT9hw_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import splitfolders\n",
        "image_size=[224,224]\n",
        "input_folder = '/content/drive/MyDrive/try1'\n",
        "splitfolders.ratio(input_folder, output=\"myTest\",\n",
        "                   seed=42, ratio=(.7, .3 ),\n",
        "                   group_prefix=None)"
      ],
      "metadata": {
        "id": "s5YJKmbK9hzn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Define the paths to the train and validation directories\n",
        "train_dir = 'myTest/train'\n",
        "val_dir = 'myTest/val'\n",
        "\n",
        "# Load the training data\n",
        "train_path = tf.keras.utils.image_dataset_from_directory(\n",
        "    train_dir,\n",
        "    image_size=(224, 224),  # same as your image_size\n",
        "    batch_size=64,          # adjust this as needed\n",
        "    label_mode='categorical'  # or 'binary' depending on your labels\n",
        ")\n",
        "\n",
        "# Load the validation data\n",
        "test_path= tf.keras.utils.image_dataset_from_directory(\n",
        "    val_dir,\n",
        "    image_size=(224, 224),  # same as your image_size\n",
        "    batch_size=64,          # adjust this as needed\n",
        "    label_mode='categorical'  # or 'binary' depending on your labels\n",
        ")"
      ],
      "metadata": {
        "id": "kGzIenST9h2Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.applications import VGG16\n",
        "VGG=VGG16(input_shape=(224,224,3),include_top=False,weights='imagenet')"
      ],
      "metadata": {
        "id": "I1Z_2NN69h4x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "VGG.trainable=False"
      ],
      "metadata": {
        "id": "2B0LvP_x9h7b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_shape = (224, 224, 3)"
      ],
      "metadata": {
        "id": "VuDrWi-19h94"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model=Sequential()\n",
        "model.add(InputLayer(shape=input_shape))\n",
        "model.add(VGG)\n",
        "model.add(GlobalAveragePooling2D())\n",
        "model.add(Dense(units=250,activation=\"relu\"))\n",
        "model.add(Dense(units=125,activation=\"relu\"))\n",
        "model.add(Dense(units=20,activation=\"softmax\"))"
      ],
      "metadata": {
        "id": "1RUqahmc9iAX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(VGG.output_shape)"
      ],
      "metadata": {
        "id": "7IjhRrbd9iDB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss=\"categorical_crossentropy\",\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "qbriB8sT9iFp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "3rIO3F1z9iIF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class myCallback(tf.keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs={}):\n",
        "    if(logs.get('accuracy')>0.98):\n",
        "      print(\"\\nReached 98% accuracy so cancelling training!\")\n",
        "      self.model.stop_training = True\n",
        "\n",
        "callbacks = myCallback()"
      ],
      "metadata": {
        "id": "eeGR9FZ_9iKf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "\n",
        "checkpoint = ModelCheckpoint(\"vgg16_1.keras\", monitor=\"val_accuracy\", verbose=1,\n",
        "                             save_best_only=True, save_weights_only=False)\n",
        "# Removed 'early' parameter as it's not part of ModelCheckpoint\n",
        "\n",
        "early_stopping = EarlyStopping(monitor=\"val_accuracy\", min_delta=0, patience=40,\n",
        "                               verbose=1, mode='auto')\n",
        "# Created a separate EarlyStopping callback"
      ],
      "metadata": {
        "id": "UYjPktHa9iNU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.callbacks import ModelCheckpoint\n",
        "\n",
        "checkpoint = ModelCheckpoint('best_model.keras', monitor='val_accuracy', save_best_only=True, verbose=1)\n"
      ],
      "metadata": {
        "id": "3fCTJamz9_R0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_training_images = len(train_path.file_paths)\n",
        "num_validation_images = len(test_path.file_paths)\n",
        "print(num_training_images)\n",
        "print(num_validation_images)"
      ],
      "metadata": {
        "id": "vKq97woV9_Ub"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "steps_per_epoch = num_training_images // 64\n",
        "validation_steps = num_validation_images // 64\n",
        "print(steps_per_epoch)\n",
        "print(validation_steps)"
      ],
      "metadata": {
        "id": "WkoXmn5Y9_X3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(x=train_path, steps_per_epoch=60, epochs=40,\n",
        "                 validation_data=test_path, validation_steps=25,\n",
        "                 callbacks=[checkpoint])"
      ],
      "metadata": {
        "id": "GqbVch3h-Mrm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(len(acc))\n",
        "\n",
        "plt.plot(epochs, acc, 'r', label='Training accuracy')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend(loc=0)\n",
        "plt.figure()\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "JnAGvShJ-Mwo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Assuming you have a trained model 'model' and test dataset 'test_path'\n",
        "# Extract all test images and labels into numpy arrays\n",
        "X_test = []\n",
        "y_test = []\n",
        "for images, labels in test_path:\n",
        "    X_test.append(images.numpy())\n",
        "    y_test.append(labels.numpy())\n",
        "\n",
        "# Concatenate the batches into a single numpy array\n",
        "X_test = np.concatenate(X_test, axis=0)\n",
        "y_test = np.concatenate(y_test, axis=0)\n",
        "\n",
        "# Predict labels for the test set\n",
        "y_pred = model.predict(X_test)\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "y_true_classes = np.argmax(y_test, axis=1)\n",
        "\n",
        "# Calculate the confusion matrix\n",
        "conf_matrix = confusion_matrix(y_true_classes, y_pred_classes)\n",
        "\n",
        "# Plot the confusion matrix\n",
        "plt.figure(figsize=(10, 10))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt='g', cmap='RdPu')\n",
        "plt.xlabel('Predicted labels')\n",
        "plt.ylabel('True labels')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()\n",
        "\n",
        "# Calculate precision, recall, F1 score, and accuracy\n",
        "report = classification_report(y_true_classes, y_pred_classes, output_dict=True)\n",
        "accuracy = report['accuracy']\n",
        "precision = report['macro avg']['precision']\n",
        "recall = report['macro avg']['recall']\n",
        "f1_score = report['macro avg']['f1-score']\n",
        "\n",
        "# Display the calculated metrics\n",
        "print(f'Validation Accuracy: {accuracy:.4f}')\n",
        "print(f'Precision: {precision:.4f}')\n",
        "print(f'Recall: {recall:.4f}')\n",
        "print(f'F1 Score: {f1_score:.4f}')"
      ],
      "metadata": {
        "id": "nqrgn17R-MzT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model on the test data\n",
        "test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
        "\n",
        "# Print the test accuracy\n",
        "print(\"Test Accuracy: {:.2f}%\".format(test_accuracy * 100))"
      ],
      "metadata": {
        "id": "io2JLbG9-M1i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the entire model to a HDF5 file\n",
        "model.save(\"my_model.h5\")"
      ],
      "metadata": {
        "id": "iZkKGBUm-M4F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the model\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "# Save the TFLite model\n",
        "with open('model.tflite', 'wb') as f:\n",
        "  f.write(tflite_model)"
      ],
      "metadata": {
        "id": "azcApFmP-M7i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('model.tflite', 'wb') as f:\n",
        "  f.write(tflite_model)"
      ],
      "metadata": {
        "id": "cfvsHG8p-mlL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming 'train_path' is your training dataset\n",
        "class_names = train_path.class_names\n",
        "\n",
        "# Save the class names to a text file\n",
        "with open('labels.txt', 'w') as f:\n",
        "  for class_name in class_names:\n",
        "    f.write(class_name + '\\n')"
      ],
      "metadata": {
        "id": "VtUeRCBc-mqN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "files.download('labels.txt')"
      ],
      "metadata": {
        "id": "2OelTEdt-mtr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}